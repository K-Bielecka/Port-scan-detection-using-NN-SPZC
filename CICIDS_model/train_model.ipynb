{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Log setting\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s %(message)s\", datefmt=\"%H:%M:%S\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR_PATH = \"data\"\n",
    "MODEL_DIR_PATH = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame):\n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    # Split features and labels\n",
    "    x = df.iloc[:, df.columns != 'Label']\n",
    "    y = df[['Label']].to_numpy()\n",
    "\n",
    "    # Scale the features between 0 ~ 1\n",
    "    scaler = MinMaxScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def reshape_dataset_cnn(x: np.ndarray) -> np.ndarray:\n",
    "    # Add padding columns\n",
    "    result = np.zeros((x.shape[0], 81))\n",
    "    result[:, :-3] = x\n",
    "\n",
    "    # Reshaping dataset\n",
    "    result = np.reshape(result, (result.shape[0], 9, 9))\n",
    "    result = result[..., tf.newaxis]\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_history(history: tf.keras.callbacks.History):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model2 accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model2 loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluation(model: keras.Model, x_test: np.ndarray, y_test: np.ndarray):\n",
    "    score = model.evaluate(x_test, y_test, verbose=False)\n",
    "    logging.info('Evaluation:\\nLoss: {}\\nAccuracy : {}\\n'.format(score[0], score[1]))\n",
    "\n",
    "    # F1 score\n",
    "    y_pred = model.predict(x_test, batch_size=1024, verbose=False)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    logging.info(\"\\n{}\".format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model() -> keras.Model:\n",
    "    # Creating layers\n",
    "    inputs = keras.layers.Input(shape=(9, 9, 1))\n",
    "    x = keras.layers.Conv2D(120, 2, activation='relu', padding=\"same\")(inputs)\n",
    "    x = keras.layers.MaxPooling2D(2)(x)\n",
    "    x = keras.layers.Conv2D(60, 3, activation='relu', padding=\"same\")(x)\n",
    "    x = keras.layers.MaxPooling2D(2)(x)\n",
    "    x = keras.layers.Conv2D(30, 4, activation='relu', padding=\"same\")(x)\n",
    "    x = keras.layers.Reshape((2, 2*30))(x)\n",
    "    x = keras.layers.GRU(64, return_sequences=True)(x)\n",
    "    x = keras.layers.GRU(32)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(15, activation='softmax')(x)\n",
    "    cnn_model = keras.Model(inputs=inputs, outputs=outputs, name='cnn')\n",
    "\n",
    "    # Compile layers\n",
    "    cnn_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['sparse_categorical_accuracy'],\n",
    "                      optimizer='adam')\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 9, 9, 1)]         0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 9, 9, 120)         600       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 4, 4, 120)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 4, 4, 60)          64860     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 2, 2, 60)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 2, 2, 30)          28830     \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 2, 60)             0         \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 2, 64)             24192     \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 32)                9408      \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 15)                495       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,385\n",
      "Trainable params: 128,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:35:46 INFO None\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_cnn_model()\n",
    "logging.info(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:23 INFO Class distribution\n",
      "0     1771379\n",
      "4      184858\n",
      "10     108072\n",
      "2      102422\n",
      "3        8234\n",
      "7        6350\n",
      "11       4717\n",
      "6        4637\n",
      "5        4399\n",
      "1        1573\n",
      "12       1206\n",
      "14        522\n",
      "9          29\n",
      "13         17\n",
      "8           9\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "cp_path = os.path.join(MODEL_DIR_PATH, \"5_2_cnn_weights-improvement-{epoch:02d}-{sparse_categorical_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(cp_path, monitor='sparse_categorical_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Training\n",
    "df = pd.read_csv(os.path.join(PROCESSED_DIR_PATH, 'train_MachineLearningCVE.csv'), skipinitialspace=True)\n",
    "logging.info(\"Class distribution\\n{}\".format(df.Label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data to fit CNN\n",
    "X, Y = preprocess(df)\n",
    "del df\n",
    "X = reshape_dataset_cnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:31 INFO *** TRAINING START ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1933/1933 [==============================] - 206s 106ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0301 - val_sparse_categorical_accuracy: 0.9881\n",
      "Epoch 2/2\n",
      "1933/1933 [==============================] - 216s 112ms/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0288 - val_sparse_categorical_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "logging.info(\"*** TRAINING START ***\")\n",
    "history = model.fit(X, Y, validation_split=0.1, epochs=2, batch_size=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:53:37 INFO *** TRAINING FINISH ***\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"*** TRAINING FINISH ***\")\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:58:46 INFO Class distribution\n",
      "10    23840\n",
      "0     19131\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "df = pd.read_csv(os.path.join(PROCESSED_DIR_PATH, 'validation_MachineLearningCVE.csv'), skipinitialspace=True)\n",
    "logging.info(\"Class distribution\\n{}\".format(df.Label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = preprocess(df)\n",
    "del df\n",
    "X = reshape_dataset_cnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:07 INFO Evaluation:\n",
      "Loss: 0.21657073497772217\n",
      "Accuracy : 0.9572967886924744\n",
      "\n",
      "C:\\Users\\olgas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\olgas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\olgas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "18:59:10 INFO \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     19131\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "          10       0.99      0.98      0.98     23840\n",
      "          11       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96     42971\n",
      "   macro avg       0.22      0.21      0.21     42971\n",
      "weighted avg       0.98      0.96      0.97     42971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, X, Y)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"*** END ***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "590fc05e1ed446e1fbcc628fa0008e96d4f6e22e106fbb51d01a946bc7e51d3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
